{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eecc1432",
   "metadata": {},
   "source": [
    "## Machine learning for marketing basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d7461",
   "metadata": {},
   "source": [
    "### Preparation for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the data\n",
    "\n",
    "# Print the data types of telco_raw dataset\n",
    "print(telco_raw.dtypes)\n",
    "\n",
    "# Print the header of telco_raw dataset\n",
    "print(telco_raw.head())\n",
    "\n",
    "# Print the number of unique values in each telco_raw column\n",
    "print(telco_raw.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6619e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "\n",
    "# Store customerID and Churn column names\n",
    "custid = ['customerID']\n",
    "target = ['Churn']\n",
    "\n",
    "# Store categorical column names\n",
    "categorical = telco_raw.nunique()[telco_raw.nunique() < 5].keys().tolist()\n",
    "\n",
    "# Remove target from the list of categorical variables\n",
    "categorical.remove(target[0])\n",
    "\n",
    "# Store numerical column names\n",
    "numerical = [x for x in telco_raw.columns if x not in custid + target + categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9da5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical and scale numerical variables\n",
    "\n",
    "# Perform one-hot encoding to categorical variables \n",
    "telco_raw = pd.get_dummies(data = telco_raw, columns = categorical, drop_first=True)\n",
    "\n",
    "# Initialize StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on numerical columns\n",
    "scaled_numerical = scaler.fit_transform(telco_raw[numerical])\n",
    "\n",
    "# Build a DataFrame from scaled_numerical\n",
    "scaled_numerical = pd.DataFrame(scaled_numerical, columns=numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf5ee0",
   "metadata": {},
   "source": [
    "### ML modeling steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and testing\n",
    "\n",
    "# Split X and Y into training and testing datasets\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "# Ensure training dataset has only 75% of original X data\n",
    "print(train_X.shape[0] / X.shape[0])\n",
    "\n",
    "# Ensure testing dataset has only 25% of original X data\n",
    "print(test_X.shape[0] / X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e25155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a decision tree\n",
    "\n",
    "# Initialize the model with max_depth set at 5\n",
    "mytree = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "treemodel = mytree.fit(train_X, train_Y)\n",
    "\n",
    "# Predict values on the testing data\n",
    "pred_Y = treemodel.predict(test_X)\n",
    "\n",
    "# Measure model performance on testing data\n",
    "accuracy_score(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict churn with decision tree\n",
    "\n",
    "# Initialize the Decision Tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 7, \n",
    "               criterion = 'gini', \n",
    "               splitter  = 'best')\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf = clf.fit(train_X, train_Y)\n",
    "\n",
    "# Predict the values on test dataset\n",
    "pred_Y = clf.predict(test_X)\n",
    "\n",
    "# Print accuracy values\n",
    "print(\"Training accuracy: \", np.round(clf.score(train_X, train_Y), 3)) \n",
    "print(\"Test accuracy: \", np.round(accuracy_score(test_Y, pred_Y), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e75f314",
   "metadata": {},
   "source": [
    "## Churn prediction and drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f02895",
   "metadata": {},
   "source": [
    "### Churn prediction fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad3e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore churn rate and split data\n",
    "# Print the unique Churn values\n",
    "print(set(telcom['Churn']))\n",
    "\n",
    "# Calculate the ratio size of each churn group\n",
    "telcom.groupby(['Churn']).size() / telcom.shape[0] * 100\n",
    "\n",
    "# Import the function for splitting data to train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test\n",
    "train, test = train_test_split(telcom, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "\n",
    "# Store column names from `telcom` excluding target variable and customer ID\n",
    "cols = [col for col in telcom.columns if col not in custid + target]\n",
    "\n",
    "# Extract training features\n",
    "train_X = train[cols]\n",
    "\n",
    "# Extract training target\n",
    "train_Y = train[target]\n",
    "\n",
    "# Extract testing features\n",
    "test_X = test[cols]\n",
    "\n",
    "# Extract testing target\n",
    "test_Y = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceaedbe",
   "metadata": {},
   "source": [
    "### Predict churn with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334af18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression model\n",
    "\n",
    "# Fit logistic regression on training data\n",
    "logreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict churn labels on testing data\n",
    "pred_test_Y = logreg.predict(test_X)\n",
    "\n",
    "# Calculate accuracy score on testing data\n",
    "test_accuracy = accuracy_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Print test accuracy score rounded to 4 decimals\n",
    "print('Test accuracy:', round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc598163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression with L1 regularization\n",
    "\n",
    "# Initialize logistic regression instance \n",
    "logreg = LogisticRegression(penalty='l1', C=0.025, solver='liblinear')\n",
    "\n",
    "# Fit the model on training data\n",
    "logreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict churn values on test data\n",
    "pred_test_Y = logreg.predict(test_X)\n",
    "\n",
    "# Print the accuracy score on test data\n",
    "print('Test accuracy:', round(accuracy_score(test_Y, pred_test_Y), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b9365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify optimal L1 penalty coefficient\n",
    "\n",
    "# Run a for loop over the range of C list length\n",
    "for index in range(0, len(C)):\n",
    "  # Initialize and fit Logistic Regression with the C candidate\n",
    "  logreg = LogisticRegression(penalty='l1', C=C[index], solver='liblinear')\n",
    "  logreg.fit(train_X, train_Y)\n",
    "  # Predict churn on the testing data\n",
    "  pred_test_Y = logreg.predict(test_X)\n",
    "  # Create non-zero count and recall score columns\n",
    "  l1_metrics[index,1] = np.count_nonzero(logreg.coef_)\n",
    "  l1_metrics[index,2] = recall_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Name the columns and print the array as pandas DataFrame\n",
    "col_names = ['C','Non-Zero Coeffs','Recall']\n",
    "print(pd.DataFrame(l1_metrics, columns=col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df689fdc",
   "metadata": {},
   "source": [
    "### Predict churn with decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f109e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit decision tree model\n",
    "\n",
    "# Initialize decision tree classifier\n",
    "mytree = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the decision tree on training data\n",
    "mytree.fit(train_X, train_Y)\n",
    "\n",
    "# Predict churn labels on testing data\n",
    "pred_test_Y = mytree.predict(test_X)\n",
    "\n",
    "# Calculate accuracy score on testing data\n",
    "test_accuracy = accuracy_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Print test accuracy\n",
    "print('Test accuracy:', round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40327ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify optimal tree depth\n",
    "\n",
    "# Run a for loop over the range of depth list length\n",
    "for index in range(0, len(depth_list)):\n",
    "  # Initialize and fit decision tree with the `max_depth` candidate\n",
    "  mytree = DecisionTreeClassifier(max_depth = depth_list[index])\n",
    "  mytree.fit(train_X, train_Y)\n",
    "  # Predict churn on the testing data\n",
    "  pred_test_Y = mytree.predict(test_X)\n",
    "  # Calculate the recall score \n",
    "  depth_tuning[index,1] = recall_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Name the columns and print the array as pandas DataFrame\n",
    "col_names = ['Max_Depth','Recall']\n",
    "print(pd.DataFrame(depth_tuning, columns=col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72669e74",
   "metadata": {},
   "source": [
    "### Identify and interpret churn drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore logistic regression coefficients\n",
    "\n",
    "# Combine feature names and coefficients into pandas DataFrame\n",
    "feature_names = pd.DataFrame(train_X.columns, columns = ['Feature'])\n",
    "log_coef = pd.DataFrame(np.transpose(logreg.coef_), columns = ['Coefficient'])\n",
    "coefficients = pd.concat([feature_names, log_coef], axis = 1)\n",
    "\n",
    "# Calculate exponent of the logistic regression coefficients\n",
    "coefficients['Exp_Coefficient'] = np.exp(coefficients['Coefficient'])\n",
    "\n",
    "# Remove coefficients that are equal to zero\n",
    "coefficients = coefficients[coefficients['Coefficient']!=0]\n",
    "\n",
    "# Print the values sorted by the exponent coefficient\n",
    "print(coefficients.sort_values(by=['Exp_Coefficient']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56019e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down decision tree rules\n",
    "\n",
    "# Export graphviz object from the trained decision tree \n",
    "exported = tree.export_graphviz(decision_tree=mytree, \n",
    "\t\t\t# Assign feature names\n",
    "            out_file=None, feature_names=train_X.columns, \n",
    "\t\t\t# Set precision to 1 and add class names\n",
    "\t\t\tprecision=1, class_names=['Not churn','Churn'], filled = True)\n",
    "\n",
    "# Call the Source function and pass the exported graphviz object\n",
    "graph = graphviz.Source(exported)\n",
    "\n",
    "# Display the decision tree\n",
    "display_image(\"/usr/local/share/datasets/decision_tree_rules.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f311b02",
   "metadata": {},
   "source": [
    "## Customer Lifetime Value (CLV) prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1124ab6",
   "metadata": {},
   "source": [
    "### Customer Lifetime Value (CLV) basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93de588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build retention and churn tables\n",
    "\n",
    "# Extract cohort sizes from the first column of cohort_counts\n",
    "cohort_sizes = cohort_counts.iloc[:,0]\n",
    "\n",
    "# Calculate retention by dividing the counts with the cohort sizes\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0)\n",
    "\n",
    "# Calculate churn\n",
    "churn = 1 - retention\n",
    "\n",
    "# Print the retention table\n",
    "print(retention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore retention and churn\n",
    "\n",
    "# Calculate the mean retention rate\n",
    "retention_rate = retention.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Calculate the mean churn rate\n",
    "churn_rate = churn.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Print rounded retention and churn rates\n",
    "print('Retention rate: {:.2f}; Churn rate: {:.2f}'.format(retention_rate, churn_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e170aa2",
   "metadata": {},
   "source": [
    "### Calculating and projecting CLV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c66cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic CLV\n",
    "\n",
    "# Calculate monthly spend per customer\n",
    "monthly_revenue = online.groupby(['CustomerID','InvoiceMonth'])['TotalSum'].sum()\n",
    "\n",
    "# Calculate average monthly spend\n",
    "monthly_revenue = np.mean(monthly_revenue)\n",
    "\n",
    "# Define lifespan to 36 months\n",
    "lifespan_months = 36\n",
    "\n",
    "# Calculate basic CLV\n",
    "clv_basic = monthly_revenue * lifespan_months\n",
    "\n",
    "# Print the basic CLV value\n",
    "print('Average basic CLV is {:.1f} USD'.format(clv_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate granular CLV\n",
    "\n",
    "# Calculate average revenue per invoice\n",
    "revenue_per_purchase = online.groupby(['InvoiceNo'])['TotalSum'].mean().mean()\n",
    "\n",
    "# Calculate average number of unique invoices per customer per month\n",
    "frequency_per_month = online.groupby(['CustomerID','InvoiceMonth'])['InvoiceNo'].nunique().mean()\n",
    "\n",
    "# Define lifespan to 36 months\n",
    "lifespan_months = 36\n",
    "\n",
    "# Calculate granular CLV\n",
    "clv_granular = revenue_per_purchase * frequency_per_month * lifespan_months\n",
    "\n",
    "# Print granular CLV value\n",
    "print('Average granular CLV is {:.1f} USD'.format(clv_granular))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate traditional CLV\n",
    "\n",
    "# Calculate monthly spend per customer\n",
    "monthly_revenue = online.groupby(['CustomerID','InvoiceMonth'])['TotalSum'].sum().mean()\n",
    "\n",
    "# Calculate average monthly retention rate\n",
    "retention_rate = retention.iloc[:,1:].mean().mean()\n",
    "\n",
    "# Calculate average monthly churn rate\n",
    "churn_rate = 1 - retention_rate\n",
    "\n",
    "# Calculate traditional CLV \n",
    "clv_traditional = monthly_revenue * (retention_rate / churn_rate)\n",
    "\n",
    "# Print traditional CLV and the retention rate values\n",
    "print('Average traditional CLV is {:.1f} USD at {:.1f} % retention_rate'.format(clv_traditional, retention_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e83f2",
   "metadata": {},
   "source": [
    "### Data preparation for purchase prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features\n",
    "\n",
    "# Define the snapshot date\n",
    "NOW = dt.datetime(2011,11,1)\n",
    "\n",
    "# Calculate recency by subtracting current date from the latest InvoiceDate\n",
    "features = online_X.groupby('CustomerID').agg({\n",
    "  'InvoiceDate': lambda x: (NOW - x.max()).days,\n",
    "  # Calculate frequency by counting unique number of invoices\n",
    "  'InvoiceNo': pd.Series.nunique,\n",
    "  # Calculate monetary value by summing all spend values\n",
    "  'TotalSum': np.sum,\n",
    "  # Calculate average and total quantity\n",
    "  'Quantity': ['mean', 'sum']}).reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "features.columns = ['CustomerID', 'recency', 'frequency', 'monetary', 'quantity_avg', 'quantity_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "\n",
    "# Build a pivot table counting invoices for each customer monthly\n",
    "cust_month_tx = pd.pivot_table(data=online, values='InvoiceNo',\n",
    "                               index=['CustomerID'], columns=['InvoiceMonth'],\n",
    "                               aggfunc=pd.Series.nunique, fill_value=0)\n",
    "\n",
    "# Store November 2011 data column name as a list\n",
    "target = ['2011-11']\n",
    "\n",
    "# Store target value as `Y`\n",
    "Y = cust_month_tx[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ffe0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and testing\n",
    "\n",
    "# Store customer identifier column name as a list\n",
    "custid = ['CustomerID']\n",
    "\n",
    "# Select feature column names excluding customer identifier\n",
    "cols = [col for col in features.columns if col not in custid]\n",
    "\n",
    "# Extract the features as `X`\n",
    "X = features[cols]\n",
    "\n",
    "# Split data to training and testing\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d8ff49",
   "metadata": {},
   "source": [
    "### Predicting customer transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict next month transactions\n",
    "\n",
    "# Initialize linear regression instance\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit the model to training dataset\n",
    "linreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict the target variable for training data\n",
    "train_pred_Y = linreg.predict(train_X)\n",
    "\n",
    "# Predict the target variable for testing data\n",
    "test_pred_Y = linreg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5331ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure model fit\n",
    "\n",
    "# Calculate root mean squared error on training data\n",
    "rmse_train = np.sqrt(mean_squared_error(train_Y, train_pred_Y))\n",
    "\n",
    "# Calculate mean absolute error on training data\n",
    "mae_train = mean_absolute_error(train_Y, train_pred_Y)\n",
    "\n",
    "# Calculate root mean squared error on testing data\n",
    "rmse_test = np.sqrt(mean_squared_error(test_Y, test_pred_Y))\n",
    "\n",
    "# Calculate mean absolute error on testing data\n",
    "mae_test = mean_absolute_error(test_Y, test_pred_Y)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('RMSE train: {}; RMSE test: {}\\nMAE train: {}, MAE test: {}'.format(rmse_train, rmse_test, mae_train, mae_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore model coefficients\n",
    "\n",
    "# Import `statsmodels.api` module\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Initialize model instance on the training data\n",
    "olsreg = sm.OLS(train_Y, train_X)\n",
    "\n",
    "# Fit the model\n",
    "olsreg = olsreg.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(olsreg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eec2af",
   "metadata": {},
   "source": [
    "## Customer segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d32a6",
   "metadata": {},
   "source": [
    "### Customer and product segmentation basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f5567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore customer product purchase dataset\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Print the header of the `wholesale` dataset\n",
    "print(wholesale.head())\n",
    "\n",
    "# Plot the pairwise relationships between the variables\n",
    "sns.pairplot(wholesale, diag_kind='kde')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4406a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand differences in variables\n",
    "\n",
    "# Create column names list and same length integer list\n",
    "x_names = wholesale.columns\n",
    "x_ix = np.arange(wholesale.shape[1])\n",
    "\n",
    "# Plot the averages data in gray and standard deviations in orange \n",
    "plt.bar(x=x_ix-0.2, height=averages, color='grey', label='Average', width=0.4)\n",
    "plt.bar(x=x_ix+0.2, height=std_devs, color='orange', label='Standard Deviation', width=0.4)\n",
    "\n",
    "# Add x-axis labels and rotate\n",
    "plt.xticks(ticks=x_ix, labels=x_names, rotation=90)\n",
    "\n",
    "# Add the legend and display the chart\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72e2b49",
   "metadata": {},
   "source": [
    "### Data preparation for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c8734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
