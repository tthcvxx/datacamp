{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2659648",
   "metadata": {},
   "source": [
    "## Machine learning for marketing basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f75f85",
   "metadata": {},
   "source": [
    "### Preparation for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the data\n",
    "\n",
    "# Print the data types of telco_raw dataset\n",
    "print(telco_raw.dtypes)\n",
    "\n",
    "# Print the header of telco_raw dataset\n",
    "print(telco_raw.head())\n",
    "\n",
    "# Print the number of unique values in each telco_raw column\n",
    "print(telco_raw.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "\n",
    "# Store customerID and Churn column names\n",
    "custid = ['customerID']\n",
    "target = ['Churn']\n",
    "\n",
    "# Store categorical column names\n",
    "categorical = telco_raw.nunique()[telco_raw.nunique() < 5].keys().tolist()\n",
    "\n",
    "# Remove target from the list of categorical variables\n",
    "categorical.remove(target[0])\n",
    "\n",
    "# Store numerical column names\n",
    "numerical = [x for x in telco_raw.columns if x not in custid + target + categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f60c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical and scale numerical variables\n",
    "\n",
    "# Perform one-hot encoding to categorical variables \n",
    "telco_raw = pd.get_dummies(data = telco_raw, columns = categorical, drop_first=True)\n",
    "\n",
    "# Initialize StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on numerical columns\n",
    "scaled_numerical = scaler.fit_transform(telco_raw[numerical])\n",
    "\n",
    "# Build a DataFrame from scaled_numerical\n",
    "scaled_numerical = pd.DataFrame(scaled_numerical, columns=numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5cb254",
   "metadata": {},
   "source": [
    "### ML modeling steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to training and testing\n",
    "\n",
    "# Split X and Y into training and testing datasets\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "# Ensure training dataset has only 75% of original X data\n",
    "print(train_X.shape[0] / X.shape[0])\n",
    "\n",
    "# Ensure testing dataset has only 25% of original X data\n",
    "print(test_X.shape[0] / X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a decision tree\n",
    "\n",
    "# Initialize the model with max_depth set at 5\n",
    "mytree = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "treemodel = mytree.fit(train_X, train_Y)\n",
    "\n",
    "# Predict values on the testing data\n",
    "pred_Y = treemodel.predict(test_X)\n",
    "\n",
    "# Measure model performance on testing data\n",
    "accuracy_score(test_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19809a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict churn with decision tree\n",
    "\n",
    "# Initialize the Decision Tree\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 7, \n",
    "               criterion = 'gini', \n",
    "               splitter  = 'best')\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf = clf.fit(train_X, train_Y)\n",
    "\n",
    "# Predict the values on test dataset\n",
    "pred_Y = clf.predict(test_X)\n",
    "\n",
    "# Print accuracy values\n",
    "print(\"Training accuracy: \", np.round(clf.score(train_X, train_Y), 3)) \n",
    "print(\"Test accuracy: \", np.round(accuracy_score(test_Y, pred_Y), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2842d76",
   "metadata": {},
   "source": [
    "## Churn prediction and drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9009a2ce",
   "metadata": {},
   "source": [
    "### Churn prediction fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore churn rate and split data\n",
    "# Print the unique Churn values\n",
    "print(set(telcom['Churn']))\n",
    "\n",
    "# Calculate the ratio size of each churn group\n",
    "telcom.groupby(['Churn']).size() / telcom.shape[0] * 100\n",
    "\n",
    "# Import the function for splitting data to train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test\n",
    "train, test = train_test_split(telcom, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0976821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "\n",
    "# Store column names from `telcom` excluding target variable and customer ID\n",
    "cols = [col for col in telcom.columns if col not in custid + target]\n",
    "\n",
    "# Extract training features\n",
    "train_X = train[cols]\n",
    "\n",
    "# Extract training target\n",
    "train_Y = train[target]\n",
    "\n",
    "# Extract testing features\n",
    "test_X = test[cols]\n",
    "\n",
    "# Extract testing target\n",
    "test_Y = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3845943",
   "metadata": {},
   "source": [
    "### Predict churn with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression model\n",
    "\n",
    "# Fit logistic regression on training data\n",
    "logreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict churn labels on testing data\n",
    "pred_test_Y = logreg.predict(test_X)\n",
    "\n",
    "# Calculate accuracy score on testing data\n",
    "test_accuracy = accuracy_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Print test accuracy score rounded to 4 decimals\n",
    "print('Test accuracy:', round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression with L1 regularization\n",
    "\n",
    "# Initialize logistic regression instance \n",
    "logreg = LogisticRegression(penalty='l1', C=0.025, solver='liblinear')\n",
    "\n",
    "# Fit the model on training data\n",
    "logreg.fit(train_X, train_Y)\n",
    "\n",
    "# Predict churn values on test data\n",
    "pred_test_Y = logreg.predict(test_X)\n",
    "\n",
    "# Print the accuracy score on test data\n",
    "print('Test accuracy:', round(accuracy_score(test_Y, pred_test_Y), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaab708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify optimal L1 penalty coefficient\n",
    "\n",
    "# Run a for loop over the range of C list length\n",
    "for index in range(0, len(C)):\n",
    "  # Initialize and fit Logistic Regression with the C candidate\n",
    "  logreg = LogisticRegression(penalty='l1', C=C[index], solver='liblinear')\n",
    "  logreg.fit(train_X, train_Y)\n",
    "  # Predict churn on the testing data\n",
    "  pred_test_Y = logreg.predict(test_X)\n",
    "  # Create non-zero count and recall score columns\n",
    "  l1_metrics[index,1] = np.count_nonzero(logreg.coef_)\n",
    "  l1_metrics[index,2] = recall_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Name the columns and print the array as pandas DataFrame\n",
    "col_names = ['C','Non-Zero Coeffs','Recall']\n",
    "print(pd.DataFrame(l1_metrics, columns=col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b902fd",
   "metadata": {},
   "source": [
    "### Predict churn with decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf581db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit decision tree model\n",
    "\n",
    "# Initialize decision tree classifier\n",
    "mytree = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit the decision tree on training data\n",
    "mytree.fit(train_X, train_Y)\n",
    "\n",
    "# Predict churn labels on testing data\n",
    "pred_test_Y = mytree.predict(test_X)\n",
    "\n",
    "# Calculate accuracy score on testing data\n",
    "test_accuracy = accuracy_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Print test accuracy\n",
    "print('Test accuracy:', round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify optimal tree depth\n",
    "\n",
    "# Run a for loop over the range of depth list length\n",
    "for index in range(0, len(depth_list)):\n",
    "  # Initialize and fit decision tree with the `max_depth` candidate\n",
    "  mytree = DecisionTreeClassifier(max_depth = depth_list[index])\n",
    "  mytree.fit(train_X, train_Y)\n",
    "  # Predict churn on the testing data\n",
    "  pred_test_Y = mytree.predict(test_X)\n",
    "  # Calculate the recall score \n",
    "  depth_tuning[index,1] = recall_score(test_Y, pred_test_Y)\n",
    "\n",
    "# Name the columns and print the array as pandas DataFrame\n",
    "col_names = ['Max_Depth','Recall']\n",
    "print(pd.DataFrame(depth_tuning, columns=col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e9c68",
   "metadata": {},
   "source": [
    "### Identify and interpret churn drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69623853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore logistic regression coefficients\n",
    "\n",
    "# Combine feature names and coefficients into pandas DataFrame\n",
    "feature_names = pd.DataFrame(train_X.columns, columns = ['Feature'])\n",
    "log_coef = pd.DataFrame(np.transpose(logreg.coef_), columns = ['Coefficient'])\n",
    "coefficients = pd.concat([feature_names, log_coef], axis = 1)\n",
    "\n",
    "# Calculate exponent of the logistic regression coefficients\n",
    "coefficients['Exp_Coefficient'] = np.exp(coefficients['Coefficient'])\n",
    "\n",
    "# Remove coefficients that are equal to zero\n",
    "coefficients = coefficients[coefficients['Coefficient']!=0]\n",
    "\n",
    "# Print the values sorted by the exponent coefficient\n",
    "print(coefficients.sort_values(by=['Exp_Coefficient']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down decision tree rules\n",
    "\n",
    "# Export graphviz object from the trained decision tree \n",
    "exported = tree.export_graphviz(decision_tree=mytree, \n",
    "\t\t\t# Assign feature names\n",
    "            out_file=None, feature_names=train_X.columns, \n",
    "\t\t\t# Set precision to 1 and add class names\n",
    "\t\t\tprecision=1, class_names=['Not churn','Churn'], filled = True)\n",
    "\n",
    "# Call the Source function and pass the exported graphviz object\n",
    "graph = graphviz.Source(exported)\n",
    "\n",
    "# Display the decision tree\n",
    "display_image(\"/usr/local/share/datasets/decision_tree_rules.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc7e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
